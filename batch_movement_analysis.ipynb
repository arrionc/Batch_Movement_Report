{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re\n",
    "import openpyxl\n",
    "from openpyxl.styles import PatternFill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Directories\n",
    "working_dir = r'C:\\Users\\ACarrion\\OneDrive - F.lli De Cecco di Filippo Fara San Martino S.p.A\\Documents\\Inventory\\WH Inventory Reports\\Working_files'\n",
    "output_dir = r'C:\\Users\\ACarrion\\OneDrive - F.lli De Cecco di Filippo Fara San Martino S.p.A\\Documents\\Inventory\\WH Inventory Reports\\Reports'\n",
    "\n",
    "# Get current date\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Find the current month's files \n",
    "files = [f for f in os.listdir(working_dir) if f.endswith(\".xlsx\")]\n",
    "\n",
    "# Read and combine data\n",
    "all_data = []\n",
    "for file in files:\n",
    "    file_path = os.path.join(working_dir,file)\n",
    "\n",
    "    # Extract date from filename\n",
    "    match = re.search(r'SAP_vs_Warehouse_all_data_(\\d{8})_\\d{4}', file)\n",
    "    if match:\n",
    "        date_str = match.group(1) # e.g. \"20250328\"\n",
    "        report_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        try:\n",
    "            date_label = report_date.strftime('%#m/%#d_QTY')\n",
    "        except:\n",
    "            date_label = report_date.strftime('%m/%d_QTY') # fallback with leading zeros \n",
    "    else:\n",
    "        # fallback: use modified date\n",
    "        mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "        date_label = mod_time.strftime('%#m/%#d_QTY')\n",
    "\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, dtype={\"Batch\": str})\n",
    "        df['Source File'] = file\n",
    "        df['Date_Label'] = date_label\n",
    "        df['Report Date'] = report_date\n",
    "        all_data.append(df[['Plant', 'Storage Location', 'Material', 'Description', 'Batch', 'Qty_SAP', 'Qty_WH', 'Delta', 'Date_Label', 'Report Date',\n",
    "                            'Manufacture Date', 'Critical Shelf Life Date', 'Expiration date', 'Number of Summers', 'Unit Value', 'Pallet number']])\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'method'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(qty_wide))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Merge everything\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m \u001b[43mqty_wide\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m(extra_info, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlant\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaterial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     29\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mmerge(last_snapshot, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlant\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaterial\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Sort columns for clean ordering\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "# Combine into single DataFrame\n",
    "if all_data:\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Get the last known Storage Location for each batch\n",
    "    combined_df_sorted = combined_df.sort_values(by='Report Date', ascending=False)\n",
    "    last_snapshot = combined_df_sorted.drop_duplicates(subset=['Plant', 'Material', 'Batch'])[['Plant','Material','Batch','Storage Location']].copy()\n",
    "    last_snapshot.rename(columns={'Storage Location': 'Last Storage Location'}, inplace=True)\n",
    "\n",
    "    # Pivot into wide format\n",
    "    qty_wide = combined_df.pivot_table(\n",
    "        index=['Plant', 'Material', 'Batch', 'Description'],\n",
    "        columns='Date_Label',\n",
    "        values='Qty_WH',\n",
    "        aggfunc='first',\n",
    "        fill_value=0\n",
    "    ).reset_index\n",
    "\n",
    "    # Get expiration and shelf life from first occurance\n",
    "    extra_info = combined_df.groupby(['Plant', 'Material', 'Batch', 'Description'], as_index=False).agg({\n",
    "        'Expiration date': 'first',\n",
    "        'Critical Shelf Life Date': 'first'\n",
    "    })\n",
    "\n",
    "    print(type(qty_wide))\n",
    "\n",
    "    # Merge everything\n",
    "    merged_df = qty_wide.merge(extra_info, on=['Plant', 'Material', 'Batch', 'Description'], how='left')\n",
    "    merged_df = merged_df.merge(last_snapshot, on=['Plant', 'Material', 'Batch'], how='left') \n",
    "\n",
    "    # Sort columns for clean ordering\n",
    "    qty_columns = sorted([col for col in merged_df.columns if '_QTY' in col],\n",
    "                         key=lambda x:datetime.strptime(x.replace('_QTY',''), '%m/%d'))\n",
    "    final_columns = ['Plant', 'Material', 'Batch', 'Description', 'Expiration date', 'Critical Shelf Life Date', 'Last Storage Location'] + qty_columns\n",
    "    merged_df = merged_df[final_columns]\n",
    "\n",
    "    # Add movement column: 'Static' if all QTYs are the same, else 'Changed'\n",
    "    def detect_movement(row):\n",
    "        values = row[qty_columns].tolist()\n",
    "        return 'Static' if all (v == values[0] for v in values) else 'Changed'\n",
    "    \n",
    "    merged_df['Batch Movement'] = merged_df.apply(detect_movement, axis=1)\n",
    "    final_columns.append['Batch Movement']\n",
    "    merged_df = merged_df[final_columns]\n",
    "\n",
    "    # Sort rows for readability\n",
    "    merged_df.sort_values(by=['Plant', 'Material', 'Batch'], inplace=True)\n",
    "\n",
    "    # Split into tabs by plant\n",
    "    plant_list = ['BP01', 'BP02', 'BP04', 'BP07']\n",
    "    output_path = os.path.join(output_dir, f\"Batch_Movement_Report_{current_date}.xlsx\")\n",
    "\n",
    "\n",
    "    with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "        for plant in plant_list:\n",
    "            plant_df = merged_df[merged_df['Plant'] == plant].copy()\n",
    "            if plant_df.empty:\n",
    "                pd.DataFrame(columns=final_columns).to_excel(writer, sheet_name=plant, index=False)\n",
    "            else:\n",
    "                plant_df.to_excel(writer, sheet_name=plant, index=False)\n",
    "            \n",
    "    # Apply alternating row colors by material\n",
    "    fill_gray = PatternFill(start_color='F2F2F2', end_color=\"F2F2F2\", fill_type='solid')\n",
    "\n",
    "    wb = openpyxl.load_workbook(output_path)\n",
    "    for sheet_name in wb.sheetnames:\n",
    "        ws = wb[sheet_name]\n",
    "        ws.freeze_panes = 'A2'\n",
    "        ws.auto_filter.ref = ws.dimensions\n",
    "\n",
    "        previous_material = None\n",
    "        use_gray = False\n",
    "\n",
    "        for row in ws.iter_rows(min_row=2, max_row=ws.max_row):\n",
    "            current_material = row[1].value # Material is in column B\n",
    "            if current_material != previous_material:\n",
    "                use_gray = not use_gray\n",
    "                previous_material = current_material\n",
    "\n",
    "            if use_gray:\n",
    "                for cell in row:\n",
    "                    cell.fill = fill_gray        \n",
    "\n",
    "    wb.save(output_path)\n",
    "    wb.close()\n",
    "    print(f\"Batch Movement Report generated: {output_path}\")\n",
    "else:\n",
    "    print(\"No data to process\")\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
